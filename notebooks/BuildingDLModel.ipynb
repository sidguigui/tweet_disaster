{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from NlpStudyFunctions import CleanDataframe\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df = pd.read_csv(r'../data/raw/train.csv')\n",
    "\n",
    "#clean the df\n",
    "#train_df = CleanDataframe(train_df_raw,'text')\n",
    "\n",
    "#split train-test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df['text'], train_df['target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Convert lists to NumPy arrays (if not already done)\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Number of words to keep based on word frequency.\n",
    "num_words = 10000\n",
    "\n",
    "# Using the Tokenizer class from Keras\n",
    "tokenizer = Tokenizer(num_words=num_words, lower=False)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Convert x_train and x_test to lists of strings if they are not already in that format\n",
    "x_train_list = x_train.tolist() if isinstance(x_train, np.ndarray) else x_train\n",
    "x_test_list = x_test.tolist() if isinstance(x_test, np.ndarray) else x_test\n",
    "\n",
    "# Convert texts to sequences of integers\n",
    "x_train_sequences = tokenizer.texts_to_sequences(x_train_list)\n",
    "x_test_sequences = tokenizer.texts_to_sequences(x_test_list)\n",
    "\n",
    "# Calculate the maximum sequence length\n",
    "max_sequence_length = max(len(x) for x in x_train_sequences)\n",
    "\n",
    "# Pad sequences to the same length\n",
    "x_train_padded = pad_sequences(x_train_sequences, maxlen=max_sequence_length)\n",
    "x_test_padded = pad_sequences(x_test_sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 104ms/step - accuracy: 0.6670 - loss: 0.6075 - val_accuracy: 0.7932 - val_loss: 0.4717\n",
      "Epoch 2/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 138ms/step - accuracy: 0.8722 - loss: 0.3205 - val_accuracy: 0.7873 - val_loss: 0.4901\n",
      "Epoch 3/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 123ms/step - accuracy: 0.9201 - loss: 0.2221 - val_accuracy: 0.7623 - val_loss: 0.5066\n",
      "Epoch 4/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 108ms/step - accuracy: 0.9578 - loss: 0.1333 - val_accuracy: 0.7584 - val_loss: 0.6253\n",
      "Epoch 5/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 109ms/step - accuracy: 0.9717 - loss: 0.0828 - val_accuracy: 0.7649 - val_loss: 0.9784\n",
      "Epoch 6/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 110ms/step - accuracy: 0.9739 - loss: 0.0609 - val_accuracy: 0.7584 - val_loss: 1.1586\n",
      "Epoch 7/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 118ms/step - accuracy: 0.9795 - loss: 0.0452 - val_accuracy: 0.7636 - val_loss: 1.3461\n",
      "Epoch 8/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 133ms/step - accuracy: 0.9832 - loss: 0.0418 - val_accuracy: 0.7584 - val_loss: 1.4311\n",
      "Epoch 9/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 118ms/step - accuracy: 0.9774 - loss: 0.0450 - val_accuracy: 0.7544 - val_loss: 1.1978\n",
      "Epoch 10/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 114ms/step - accuracy: 0.9812 - loss: 0.0395 - val_accuracy: 0.7380 - val_loss: 1.3415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20d26899370>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Bidirectional, Conv1D, MaxPooling1D, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Assuming num_words and max_sequence_length are defined\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=200, input_length=max_sequence_length))\n",
    "model.add(LSTM(128, return_sequences=True, dropout=0.2))\n",
    "model.add(LSTM(512, dropout=0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_padded, y_train, validation_data=(x_test_padded, y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.7355 - loss: 1.4337\n",
      "Test Loss: 1.3415\n",
      "Test Accuracy: 0.7380\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test_padded, y_test)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model.save(r'../models/DL_MODEL.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "text_test_df = pd.read_csv(r'../data/raw/test.csv')\n",
    "\n",
    "text_test_df = np.array(text_test_df['text'])\n",
    "\n",
    "tokenizer.fit_on_texts(text_test_df)\n",
    "\n",
    "text_test_df_list = text_test_df.tolist() if isinstance(text_test_df, np.ndarray) else text_test_df\n",
    "\n",
    "test_df_sequences = tokenizer.texts_to_sequences(text_test_df_list)\n",
    "\n",
    "# Pad sequences to the same length\n",
    "test_df_padded = pad_sequences(test_df_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "model = keras.models.load_model(r'../models/DL_MODEL.keras')\n",
    "\n",
    "pred = model.predict(test_df_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(pred)\n",
    "\n",
    "# Assuming `predictions` is already a DataFrame\n",
    "predictions.columns = ['column_0', 'column_1']\n",
    "\n",
    "# Update `column_0` based on the comparison\n",
    "for index, row in predictions.iterrows():\n",
    "    if row['column_0'] < row['column_1']:\n",
    "        predictions.at[index, 'column_0'] = 1\n",
    "    else:\n",
    "        predictions.at[index, 'column_0'] = 0\n",
    "\n",
    "# Convert `column_0` to integer type\n",
    "predictions['column_0'] = predictions['column_0'].astype(int)\n",
    "\n",
    "# Create the binary_predictions variable\n",
    "binary_predictions = predictions['column_0']\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission = pd.DataFrame({'id': test_df_raw['id'], 'target': binary_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3263.000000</td>\n",
       "      <td>3263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5427.152927</td>\n",
       "      <td>0.523751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3146.427221</td>\n",
       "      <td>0.499512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2683.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8176.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10875.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       target\n",
       "count   3263.000000  3263.000000\n",
       "mean    5427.152927     0.523751\n",
       "std     3146.427221     0.499512\n",
       "min        0.000000     0.000000\n",
       "25%     2683.000000     0.000000\n",
       "50%     5500.000000     1.000000\n",
       "75%     8176.000000     1.000000\n",
       "max    10875.000000     1.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.to_csv(r'../data/final/submission.csv',index=False)\n",
    "\n",
    "submission = pd.read_csv(r'../data/final/submission.csv')\n",
    "submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    1709\n",
       "0    1554\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       0\n",
       "2   3       1\n",
       "3   9       0\n",
       "4  11       1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25.4k/25.4k [00:00<00:00, 48.1kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to Natural Language Processing with Disaster Tweets"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kaggle\n",
    "\n",
    "# Replace 'submission.csv' with the path to your submission file\n",
    "submission_file = r'../data/final/submission.csv'\n",
    "\n",
    "# Replace 'Message' with your submission message\n",
    "submission_message = 'DL model try'\n",
    "\n",
    "# Call the submit function from kaggle package\n",
    "kaggle.api.competition_submit(submission_file, submission_message, competition='nlp-getting-started')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salesforce_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
