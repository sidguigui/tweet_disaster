{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from NlpStudyFunctions import CleanDataframe\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df_raw = pd.read_csv(r'../data/raw/train.csv')\n",
    "\n",
    "#clean the df\n",
    "train_df = CleanDataframe(train_df_raw,'text')\n",
    "\n",
    "#split train-test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df['text'], train_df['target'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Convert lists to NumPy arrays (if not already done)\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Number of words to keep based on word frequency.\n",
    "num_words = 10000\n",
    "\n",
    "# Using the Tokenizer class from Keras\n",
    "tokenizer = Tokenizer(num_words=num_words, lower=False)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Convert x_train and x_test to lists of strings if they are not already in that format\n",
    "x_train_list = x_train.tolist() if isinstance(x_train, np.ndarray) else x_train\n",
    "x_test_list = x_test.tolist() if isinstance(x_test, np.ndarray) else x_test\n",
    "\n",
    "# Convert texts to sequences of integers\n",
    "x_train_sequences = tokenizer.texts_to_sequences(x_train_list)\n",
    "x_test_sequences = tokenizer.texts_to_sequences(x_test_list)\n",
    "\n",
    "# Calculate the maximum sequence length\n",
    "max_sequence_length = max(len(x) for x in x_train_sequences)\n",
    "\n",
    "# Pad sequences to the same length\n",
    "x_train_padded = pad_sequences(x_train_sequences, maxlen=max_sequence_length)\n",
    "x_test_padded = pad_sequences(x_test_sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 165ms/step - accuracy: 0.5750 - loss: 9.6114 - val_accuracy: 0.5739 - val_loss: 5.1439\n",
      "Epoch 2/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 164ms/step - accuracy: 0.6107 - loss: 4.2679 - val_accuracy: 0.7794 - val_loss: 2.2183\n",
      "Epoch 3/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 159ms/step - accuracy: 0.8448 - loss: 1.7851 - val_accuracy: 0.8056 - val_loss: 1.1063\n",
      "Epoch 4/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 154ms/step - accuracy: 0.9092 - loss: 0.7729 - val_accuracy: 0.7873 - val_loss: 0.7166\n",
      "Epoch 5/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 146ms/step - accuracy: 0.9383 - loss: 0.3857 - val_accuracy: 0.7925 - val_loss: 0.6256\n",
      "Epoch 6/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 173ms/step - accuracy: 0.9517 - loss: 0.2256 - val_accuracy: 0.7643 - val_loss: 0.7546\n",
      "Epoch 7/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 159ms/step - accuracy: 0.9625 - loss: 0.1537 - val_accuracy: 0.7748 - val_loss: 0.6680\n",
      "Epoch 8/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 194ms/step - accuracy: 0.9702 - loss: 0.1258 - val_accuracy: 0.7630 - val_loss: 0.8117\n",
      "Epoch 9/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 184ms/step - accuracy: 0.9804 - loss: 0.0886 - val_accuracy: 0.7702 - val_loss: 0.8139\n",
      "Epoch 10/10\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 141ms/step - accuracy: 0.9850 - loss: 0.0745 - val_accuracy: 0.7754 - val_loss: 0.7683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f1c7844080>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Bidirectional, Conv1D, MaxPooling1D, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Assuming num_words and max_sequence_length are defined\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_words, output_dim=500, input_length=max_sequence_length, trainable=True))\n",
    "\n",
    "# Add Conv1D layer\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Use Bidirectional LSTM\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Bidirectional(LSTM(256, dropout=0.2, recurrent_dropout=0.2)))\n",
    "\n",
    "# Add more Dense layers with regularization\n",
    "model.add(Dense(1024, activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Final output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model with a different optimizer and learning rate\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x_train_padded, y_train, validation_data=(x_test_padded, y_test), epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7460 - loss: 1.1323\n",
      "Test Loss: 1.0533\n",
      "Test Accuracy: 0.7603\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test_padded, y_test)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model.save(r'../models/DL_MODEL.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "test_df_raw = pd.read_csv(r'../data/raw/test.csv')\n",
    "\n",
    "# Clean the df\n",
    "text_test_df = CleanDataframe(test_df_raw,'text')\n",
    "\n",
    "# Convert lists to NumPy arrays (if not already done)\n",
    "text_test_df = np.array(text_test_df)\n",
    "\n",
    "# Convert back to list\n",
    "text_test_df = text_test_df.tolist() if isinstance(text_test_df, np.ndarray) else text_test_df\n",
    "\n",
    "# Convert numbers to strings\n",
    "text_test_df = [str(item) for item in text_test_df]\n",
    "\n",
    "# Now, proceed with tokenization\n",
    "tokenizer.fit_on_texts(text_test_df)\n",
    "\n",
    "# Fit tokenizer on text\n",
    "tokenizer.fit_on_texts(text_test_df)\n",
    "\n",
    "test_df_sequences = tokenizer.texts_to_sequences(text_test_df)\n",
    "\n",
    "# Calculate the maximum sequence length\n",
    "max_sequence_length = max(len(x) for x in test_df_sequences)\n",
    "\n",
    "# Pad sequences to the same length\n",
    "test_df_padded = pad_sequences(test_df_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "model = keras.models.load_model(r'../models/DL_MODEL.keras')\n",
    "\n",
    "predictions = model.predict(test_df_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  target\n",
      "0         0       0\n",
      "1         2       0\n",
      "2         3       1\n",
      "3         9       0\n",
      "4        11       1\n",
      "...     ...     ...\n",
      "3258  10861       0\n",
      "3259  10865       0\n",
      "3260  10868       1\n",
      "3261  10874       0\n",
      "3262  10875       0\n",
      "\n",
      "[3263 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions = pd.DataFrame(predictions)\n",
    "\n",
    "# Assuming `predictions` is already a DataFrame\n",
    "predictions.columns = ['column_0', 'column_1']\n",
    "\n",
    "# Update `column_0` based on the comparison\n",
    "for index, row in predictions.iterrows():\n",
    "    if row['column_0'] < row['column_1']:\n",
    "        predictions.at[index, 'column_0'] = 1\n",
    "    else:\n",
    "        predictions.at[index, 'column_0'] = 0\n",
    "\n",
    "# Convert `column_0` to integer type\n",
    "predictions['column_0'] = predictions['column_0'].astype(int)\n",
    "\n",
    "# Create the binary_predictions variable\n",
    "binary_predictions = predictions['column_0']\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission = pd.DataFrame({'id': test_df_raw['id'], 'target': binary_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3263.000000</td>\n",
       "      <td>3263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5427.152927</td>\n",
       "      <td>0.403923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3146.427221</td>\n",
       "      <td>0.490758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2683.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8176.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10875.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       target\n",
       "count   3263.000000  3263.000000\n",
       "mean    5427.152927     0.403923\n",
       "std     3146.427221     0.490758\n",
       "min        0.000000     0.000000\n",
       "25%     2683.000000     0.000000\n",
       "50%     5500.000000     0.000000\n",
       "75%     8176.000000     1.000000\n",
       "max    10875.000000     1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.to_csv(r'../data/final/submission.csv',index=False)\n",
    "\n",
    "submission = pd.read_csv(r'../data/final/submission.csv')\n",
    "submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "\n",
    "# Replace 'submission.csv' with the path to your submission file\n",
    "submission_file = r'../data/final/submission.csv'\n",
    "\n",
    "# Replace 'Message' with your submission message\n",
    "submission_message = 'DL model try'\n",
    "\n",
    "# Call the submit function from kaggle package\n",
    "#kaggle.api.competition_submit(submission_file, submission_message, competition='nlp-getting-started')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salesforce_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
