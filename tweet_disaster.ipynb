{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(r'train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_right_df = train_df[train_df[\"target\"]==1]\n",
    "train_wrong_df = train_df[train_df[\"target\"]==0]\n",
    "train_right_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hipóteses\n",
    "- O tamanho dos tweets infuenciam\n",
    "- Número de palavras no tweet influenciam\n",
    "- As palavras mais repetidas são influentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_right_words_df = []\n",
    "train_wrong_words_df = []\n",
    "\n",
    "## let's get counts for the first 5 tweets in the data\n",
    "for index, row in train_right_df.iterrows():\n",
    "    train_right_words_df.append(len(row[\"text\"].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 41., 174., 425., 625., 418., 711., 510., 272.,  83.,  12.]),\n",
       " array([ 2. ,  4.8,  7.6, 10.4, 13.2, 16. , 18.8, 21.6, 24.4, 27.2, 30. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_right_words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([100., 345., 539., 690., 684., 728., 585., 416., 204.,  51.]),\n",
       " array([ 1.,  4.,  7., 10., 13., 16., 19., 22., 25., 28., 31.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for index, row in train_wrong_df.iterrows():\n",
    "    train_wrong_words_df.append(len(row[\"text\"].split()))\n",
    "plt.hist(train_wrong_words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5738673670387393\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming train_df is your DataFrame and it has columns \"text\" and \"target\"\n",
    "\n",
    "# Calculate count of words\n",
    "train_df[\"count_words\"] = train_df[\"text\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df[[\"count_words\"]], train_df[\"target\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Set the threshold\n",
    "threshold = 0.5\n",
    "\n",
    "# Classify predictions\n",
    "y_pred_discrete = (y_pred > threshold).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_discrete)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(r'test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"count_words\"] = test_df[\"text\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Predict the target variable using the trained model\n",
    "test_df[\"target\"] = model.predict(test_df[[\"count_words\"]])\n",
    "\n",
    "# Set the threshold\n",
    "threshold = 0.5\n",
    "\n",
    "# Classify predictions\n",
    "test_df[\"target\"] = (test_df[\"target\"] > threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Carregando o modelo e o tokenizer\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Function for cleaning tweets\n",
    "def clean_tweet(tweet):\n",
    "    tweet_words = []\n",
    "    for word in tweet.split():\n",
    "        if word.startswith('@') and len(word) > 1:\n",
    "            word = '@user'\n",
    "        elif word.startswith('http') and len(word) > 1:\n",
    "            word = 'http'\n",
    "        tweet_words.append(word)\n",
    "    return \" \".join(tweet_words)\n",
    "\n",
    "# Function for performing inference\n",
    "def classify_tweets(tweets):\n",
    "    encoded_inputs = tokenizer(tweets, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = model(**encoded_inputs)\n",
    "    scores = softmax(outputs.logits.detach().numpy(), axis=1)\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Load your data into train_df\n",
    "\n",
    "# Clean tweets\n",
    "train_df['text_clean'] = train_df['text'].apply(clean_tweet)\n",
    "\n",
    "# Batch processing\n",
    "batch_size = 32\n",
    "sentiment_scores_list = []\n",
    "for i in range(0, len(train_df), batch_size):\n",
    "    batch_tweets = train_df['text_clean'][i:i+batch_size].tolist()\n",
    "    scores = classify_tweets(batch_tweets)\n",
    "    sentiment_scores_list.extend(scores)\n",
    "\n",
    "# Add sentiment scores to the original DataFrame\n",
    "sentiment_df = pd.DataFrame(sentiment_scores_list, columns=['negative_score', 'neutral_score', 'positive_score'])\n",
    "result_df = pd.concat([train_df.reset_index(drop=True), sentiment_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Write result to CSV\n",
    "result_df.to_csv(r'result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'result.csv')\n",
    "\n",
    "train_df['max_column'] = train_df[['negative_score', 'neutral_score', 'positive_score']].idxmax(axis=1)\n",
    "\n",
    "train_df.drop(columns=['negative_score', 'neutral_score', 'positive_score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>count_words</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>max_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  count_words                                         text_clean  \\\n",
       "0       1           13  Our Deeds are the Reason of this #earthquake M...   \n",
       "1       1            7             Forest fire near La Ronge Sask. Canada   \n",
       "2       1           22  All residents asked to 'shelter in place' are ...   \n",
       "3       1            8  13,000 people receive #wildfires evacuation or...   \n",
       "4       1           16  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "  max_column  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5602094240837696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60       412\n",
      "           1       0.52      0.50      0.51       352\n",
      "\n",
      "    accuracy                           0.56       764\n",
      "   macro avg       0.56      0.56      0.56       764\n",
      "weighted avg       0.56      0.56      0.56       764\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guibe\\AppData\\Local\\Temp\\ipykernel_1104\\421947618.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['max_column'].replace({'neutral_score': 1, 'negative_score': 0, 'other_value': 2}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming X is your feature matrix and y is your target vector (containing 0s and 1s)\n",
    "# Splitting the data into training and testing sets\n",
    "\n",
    "# Assuming your DataFrame is named train_df\n",
    "\n",
    "train_df['max_column'].replace({'neutral_score': 1, 'negative_score': 0, 'other_value': 2}, inplace=True)\n",
    "train_df['max_column'] = pd.to_numeric(train_df['max_column'], errors='coerce')\n",
    "\n",
    "train_df.dropna(inplace=True)\n",
    "\n",
    "combined_features = pd.concat([train_df['max_column'], train_df['count_words']], axis=1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, train_df['target'], test_size=0.17, random_state=42)\n",
    "\n",
    "\n",
    "# Creating a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fitting the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the testing data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Printing classification report\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(test_df), batch_size):\n\u001b[0;32m     41\u001b[0m     batch_tweets \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_clean\u001b[39m\u001b[38;5;124m'\u001b[39m][i:i\u001b[38;5;241m+\u001b[39mbatch_size]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m---> 42\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_tweets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_tweets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     sentiment_scores_list\u001b[38;5;241m.\u001b[39mextend(scores)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Add sentiment scores to the original DataFrame\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[44], line 27\u001b[0m, in \u001b[0;36mclassify_tweets\u001b[1;34m(tweets)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_tweets\u001b[39m(tweets):\n\u001b[0;32m     26\u001b[0m     encoded_inputs \u001b[38;5;241m=\u001b[39m tokenizer(tweets, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 27\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoded_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     scores \u001b[38;5;241m=\u001b[39m softmax(outputs\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1195\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1193\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1195\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1206\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1207\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:832\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    823\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    825\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    826\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    827\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    830\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    831\u001b[0m )\n\u001b[1;32m--> 832\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    844\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    845\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:521\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    510\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    511\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    512\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    518\u001b[0m         output_attentions,\n\u001b[0;32m    519\u001b[0m     )\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:452\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    449\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    450\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 452\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    457\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\transformers\\pytorch_utils.py:238\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:464\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m--> 464\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:362\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 362\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    363\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guibe\\anaconda3\\envs\\kaggle_project\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Clean tweets\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Carregando o modelo e o tokenizer\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Function for cleaning tweets\n",
    "def clean_tweet(tweet):\n",
    "    tweet_words = []\n",
    "    for word in tweet.split():\n",
    "        if word.startswith('@') and len(word) > 1:\n",
    "            word = '@user'\n",
    "        elif word.startswith('http') and len(word) > 1:\n",
    "            word = 'http'\n",
    "        tweet_words.append(word)\n",
    "    return \" \".join(tweet_words)\n",
    "\n",
    "# Function for performing inference\n",
    "def classify_tweets(tweets):\n",
    "    encoded_inputs = tokenizer(tweets, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = model(**encoded_inputs)\n",
    "    scores = softmax(outputs.logits.detach().numpy(), axis=1)\n",
    "    return scores\n",
    "\n",
    "test_df = pd.read_csv(r'test.csv')\n",
    "\n",
    "test_df[\"count_words\"] = test_df[\"text\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "test_df['text_clean'] = test_df['text'].apply(clean_tweet)\n",
    "\n",
    "# Batch processing\n",
    "batch_size = 32\n",
    "sentiment_scores_list = []\n",
    "for i in range(0, len(test_df), batch_size):\n",
    "    batch_tweets = test_df['text_clean'][i:i+batch_size].tolist()\n",
    "    scores = classify_tweets(batch_tweets)\n",
    "    sentiment_scores_list.extend(scores)\n",
    "\n",
    "# Add sentiment scores to the original DataFrame\n",
    "sentiment_df = pd.DataFrame(sentiment_scores_list, columns=['negative_score', 'neutral_score', 'positive_score'])\n",
    "result_df = pd.concat([test_df.reset_index(drop=True), sentiment_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the testing data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Printing classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = result_df[[\"id\",\"target\"]]\n",
    "submission.to_csv(r'submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaggle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkaggle\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Replace 'submission.csv' with the path to your submission file\u001b[39;00m\n\u001b[0;32m      4\u001b[0m submission_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kaggle'"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "\n",
    "# Replace 'submission.csv' with the path to your submission file\n",
    "submission_file = 'submission.csv'\n",
    "\n",
    "# Replace 'Message' with your submission message\n",
    "submission_message = 'First try'\n",
    "\n",
    "# Call the submit function from kaggle package\n",
    "#kaggle.api.competition_submit(submission_file, submission_message, competition='nlp-getting-started')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "letterboxd_projeto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
